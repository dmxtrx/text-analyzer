{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инструмент для анализа текста\n",
    "\n",
    "**Основная задача**: Создать инструмент для анализа текста, который обрабатывает текстовые записи (например, отзывы пользователей, статьи или отрывки из книг) и предоставляет некоторые выводы, статистику и преобразования. После этого применить инструмент для анализа текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"\"\"**_Stellar Blade_** is the latest exclusive to hit the PlayStation 5 that excels\n",
    "at delivering a highly riveting action RPG. Shift Up Corporation has crafted an\n",
    "impressive linear title that takes influences from some of the most renowned\n",
    "games in recent times. **Even though the parallels are quite apparent, _Stellar\n",
    "Blade_ doesn’t try to reinvent the wheel but rather refines what players are\n",
    "already familiar with.**  _Stellar Blade_ is centered around EVE, a member of\n",
    "the 7th Airborne Division w...\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Сбор и предварительная обработка данных\n",
    "\n",
    "Написать функцию `preprocess_text`, которая принимает на вход текст и очищает его. Функция должна:\n",
    "   - Преобразовывать текст в строчные буквы.\n",
    "   - Удалять ненужные знаки препинания и специальные символы, но сохранять знаки препинания в конце предложения (`.` `!` `?`).\n",
    "   - Удалить лишние пробелы между словами.\n",
    "   - Вернуть очищенный текст.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello world! this is a test.', 'python is fun! coding', 'spaces should be removed.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def preprocess_text(text):\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.!?]', '', text) # del all trash symbols\n",
    "    text = re.sub(r'\\s+', ' ', text) # del all trash bspaces\n",
    "    text = re.sub(r'\\s([.!?])', r'\\1', text) # del bsaces before !?.\n",
    "    text = re.sub(r'([.!?]){2,}', r'\\1', text) # del acsess !?.\n",
    "    return text\n",
    "\n",
    "input_texts = [\n",
    "    \"Hello, World!\\n   This is a test...\",\n",
    "    \"Python is fun!!! #coding\",\n",
    "    \"  Spaces should be    removed.\"\n",
    "]\n",
    "\n",
    "processed_texts = [preprocess_text(text) for text in input_texts]\n",
    "print(processed_texts,end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Анализ частоты слов\n",
    "\n",
    "Написать функцию `word_frequency`, которая берет очищенный текст (из части 1) и возвращает словарь, где ключами являются слова, а значениями - их частота в тексте. Функция должна:\n",
    "   - Подсчитать, как часто каждое слово встречается в тексте.\n",
    "   - Игнорировать любые общие стоп-слова. Вы можете использовать предопределенный список, приведенный ниже, или использовать свой собственный. Подумайте о том, чтобы сделать его настраиваемым.\n",
    "\n",
    "**Предопределённые стоп-слова**:\n",
    "```python\n",
    "stop_words = [\"and\", \"the\", \"is\", \"in\", \"it\", \"you\", \"that\", \"to\", \"of\", \"a\", \"with\", \"for\", \"on\", \"this\", \"at\", \"by\", \"an\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(text, stop_words = None):\n",
    "    if stop_words is None:\n",
    "        stop_words = [\"i\", \"and\", \"the\", \"is\", \"in\", \"it\", \"you\", \"that\", \"to\", \"of\", \n",
    "                     \"a\", \"with\", \"for\", \"on\", \"this\", \"at\", \"by\", \"an\", \"be\", \"should\"]\n",
    "    words = text.lower().split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    clean_words = [word.strip('.!?,') for word in filtered_words]\n",
    "    freq_dict = {}\n",
    "    for word in clean_words:\n",
    "        freq_dict[word] = freq_dict.get(word, 0) + 1\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Извлечение информации\n",
    "\n",
    "Написать функцию `extract_information`, которая берет неочищенный текст (**не из части 1**) и извлекает определенные типы информации на основе настраиваемых шаблонов regex, предоставленных в качестве keyword-аргументов. Функция должна возвращать словарь, в котором ключи - это типы совпадений, а значения - списки найденных совпадений.\n",
    "\n",
    "**Поддерживаемые типы информации**:\n",
    "1. Адреса электронных почт\n",
    "2. Телефонные номера\n",
    "3. Даты\n",
    "4. Время\n",
    "5. Цены\n",
    "6. Дополнительные данные по желанию пользователя\n",
    "\n",
    "**Инструкции**:\n",
    "- Функция должна принимать следующие keyword-only аргументы с шаблонами regex по умолчанию:\n",
    "  - `email_pattern` (default: `r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'`)\n",
    "  - `phone_pattern` (default: `r'\\+?\\d[\\d -]{8,12}\\d'`)\n",
    "  - `date_pattern` (default: `r'\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}\\b'`)\n",
    "  - `time_pattern` (default: `r'\\b\\d{1,2}:\\d{2}\\s*[APap][mM]?\\b'`)\n",
    "  - `price_pattern` (по умолчанию: `r'\\$\\d+(?:\\.\\d{2})?'`)\n",
    "  - `**extra_patterns`: Дополнительные аргументы для пользовательских шаблонов.\n",
    "\n",
    "- Функция должна:\n",
    "  - Найти все совпадения в по каждому шаблону во всём тексте.\n",
    "  - Хранить совпадения в словаре результатов под соответствующим типом.\n",
    "  - Возвращать словарь со всеми найденными совпадениями.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_information(text, *,\n",
    "                        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}',\n",
    "                        phone_pattern = r'\\+?\\d?\\(?\\d{3}\\)?[\\d -]{8,12}\\d',\n",
    "                        date_pattern = r'\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}\\b',\n",
    "                        time_pattern = r'\\b\\d{1,2}:\\d{2}\\s*[APap][mM]?\\b',\n",
    "                        price_pattern = r'\\$\\d+(?:\\.\\d{2})?', \n",
    "                        **patterns):\n",
    "    default_patterns = {'emails': re.findall(email_pattern, text),\n",
    "        'phone_numbers': re.findall(phone_pattern, text),\n",
    "        'dates': re.findall(date_pattern, text),\n",
    "        'times': re.findall(time_pattern, text),\n",
    "        'prices': re.findall(price_pattern, text)}\n",
    "    for name, pattern in patterns.items():\n",
    "        default_patterns[name] = re.findall(pattern, text)\n",
    "    return default_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 4: Анализ настроения\n",
    "\n",
    "Написать функцию `analyze_sentiment`, которая берет очищенный текст (из задания 1) и анализирует его настроение на основе заранее определенных положительных и отрицательных слов. Функция должна возвращать оценку настроения текста.\n",
    "\n",
    "**Предназначенные списки слов**:\n",
    "- **Положительные слова** (по умолчанию):\n",
    "```python\n",
    "positive_words = [\"good\", \"great\", \"happy\", \"joy\", \"excellent\", \"fantastic\", \"love\", \"best\"]\n",
    "```\n",
    "- **Негативные слова** (по умолчанию):\n",
    "```python\n",
    "negative_words = [\"bad\", \"sad\", \"hate\", \"terrible\", \"awful\", \"poor\", \"worst\"]\n",
    "```\n",
    "\n",
    "- Функция должна принимать следующие keyword-аргументы:\n",
    "  - `positive_words`: Список положительных слов (по умолчанию, как показано выше).\n",
    "  - `negative_words`: Список отрицательных слов (по умолчанию, как показано выше).\n",
    "\n",
    "- Функция должна:\n",
    "  - Подсчитать количество положительных и отрицательных слов в каждой записи текста.\n",
    "  - Рассчитать балл настроения для каждой записи:\n",
    "    - Sentiment Score = (Number of Positive Words - Number of Negative Words)\n",
    "  - Вернуть оценку настроения текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text, positive_words=None, negative_words=None):\n",
    "    if positive_words is None:\n",
    "        positive_words = [\"good\", \"great\", \"happy\", \"joy\", \"excellent\", \n",
    "                         \"fantastic\", \"love\", \"best\", \"amazing\", \"fun\"]\n",
    "    if negative_words is None:\n",
    "        negative_words = [\"bad\", \"sad\", \"hate\", \"terrible\", \"awful\", \n",
    "                         \"poor\", \"worst\"]\n",
    "    cleaned_words = [word.strip('.!?').lower() for word in text.split()]\n",
    "    positive_count = sum(cleaned_words.count(word) for word in positive_words)\n",
    "    negative_count = sum(cleaned_words.count(word) for word in negative_words)\n",
    "    sentiment_score = positive_count - negative_count \n",
    "    return sentiment_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 5: Обобщение текста\n",
    "\n",
    "Написать функцию `summarize_text`, которая берет очищенный текст (из части 1) и обобщает его, извлекая наиболее важные предложения на основе их релевантности. Функция должна позволять пользователю указывать в качестве параметра желаемый коэффициент сжатия.\n",
    "\n",
    "- Функция должна принимать следующие параметры:\n",
    "  - `text`: Одиночный очищенный текст, который нужно обобщить.\n",
    "  - `compression_ratio`: Число от 0 до 1, представляющее желаемое сжатие (например, 0,6 для 60-процентного обобщения).\n",
    "  - `min_threshold`: Целое число, указывающее минимальное количество оставшихся предложений (по умолчанию 2).\n",
    "\n",
    "- Функция должна:\n",
    "  - Разделить текст на предложения.\n",
    "  - Ранжировать предложения на основе их важности (можно использовать простые метрики, такие как длина, частота слов, наличие значимых слов или любые другие метрики, которые вы считаете наиболее подходящими).\n",
    "  - Используйте рекурсивный подход для динамического отбора предложений с наивысшим рейтингом, удаляя каждое выбранное предложение и заново ранжируя оставшиеся, пока не будет достигнут желаемый коэффициент сжатия.\n",
    "  - Верните обобщенный текст в виде строки, состоящей из выбранных предложений.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stellar blade is the latest exclusive to hit the playstation 5 that excels at delivering a highly riveting action rpg. shift up corporation has crafted an impressive linear title that takes influences from some of the most renowned games in recent times. even though the parallels are quite apparent stellar blade doesnt try to reinvent the wheel but rather refines what players are already familiar with. stellar blade is centered around eve a member of the 7th airborne division w.\n",
      "Summary:\n",
      "shift up corporation has crafted an impressive linear title that takes influences from some of the most renowned games in recent times. stellar blade is centered around eve a member of the 7th airborne division w.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def summarize_text(text, compression_ratio=0.6, min_threshold=2):\n",
    "    if not text or not text.strip():\n",
    "        return \"\"\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]', text) if s.strip()]\n",
    "    target_length = max(min_threshold, int(len(sentences) * (1 - compression_ratio)))\n",
    "    if len(sentences) <= target_length:\n",
    "        return '. '.join(sentences) + '.'\n",
    "    \n",
    "    def rank_sentences(sentences):\n",
    "        word_frequencies = {}\n",
    "        for sentence in sentences:\n",
    "            for word in sentence.split():\n",
    "                word_lower = word.lower()\n",
    "                if word_lower not in word_frequencies:\n",
    "                    word_frequencies[word_lower] = 0\n",
    "                word_frequencies[word_lower] += 1\n",
    "        sentence_scores = {}\n",
    "        for sentence in sentences:\n",
    "            words = sentence.split()\n",
    "            sentence_scores[sentence] = sum(word_frequencies[word.lower()] for word in words)\n",
    "        return sentence_scores\n",
    "    \n",
    "    def recursive_summarization(sentences, target_length):\n",
    "        if len(sentences) <= target_length:\n",
    "            return sentences\n",
    "        sentence_scores = rank_sentences(sentences)\n",
    "        highest_ranked = max(sentence_scores, key=sentence_scores.get)\n",
    "        reduced_sentences = [s for s in sentences if s != highest_ranked]\n",
    "        return recursive_summarization(reduced_sentences, target_length)\n",
    "    \n",
    "    original_sentences = sentences[:]\n",
    "    summarized_sentences = recursive_summarization(sentences, target_length)\n",
    "    summarized_sentences.sort(key=lambda sentence: original_sentences.index(sentence))\n",
    "\n",
    "    return '. '.join(summarized_sentences) + '.'\n",
    "\n",
    "\n",
    "t = '''**_Stellar Blade_** is the latest exclusive to hit the PlayStation 5 that excels\n",
    "at delivering a highly riveting action RPG. Shift Up Corporation has crafted an\n",
    "impressive linear title that takes influences from some of the most renowned\n",
    "games in recent times. **Even though the parallels are quite apparent, _Stellar\n",
    "Blade_ doesn’t try to reinvent the wheel but rather refines what players are\n",
    "already familiar with.**  _Stellar Blade_ is centered around EVE, a member of\n",
    "the 7th Airborne Division w...'''\n",
    "\n",
    "test_text = preprocess_text(t)\n",
    "print(test_text)\n",
    "summary = summarize_text((test_text))\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 6: Визуализация частоты слов\n",
    "\n",
    "Написать функцию `visualize_word_frequency`, которая берет словарь частот слов (полученный в части 2) и визуализирует частоты в текстовом формате.\n",
    "\n",
    "- Функция должна принимать словарь, в котором ключами являются слова, а значениями - их частоты.\n",
    "- На выходе должно отображаться каждое слово, за которым следует горизонтальная полоса, представляющая его частоту. Для создания полос используйте простой символ (например, `*`).\n",
    "- Длину каждой полосы можно масштабировать в зависимости от максимальной частоты, чтобы обеспечить читабельность.\n",
    "- Функция должна иметь параметр `max_threshold`, чтобы ограничить количество строк в выводе (по умолчанию 20).\n",
    "- Вывод должен быть отсортирован от наиболее до наименее часто используемых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_word_frequency(word_frequency, max_threshold=20):\n",
    "    sorted_words = sorted(word_frequency.items(), key=lambda x: x[1], reverse=True)[:max_threshold]\n",
    "    for word, value in sorted_words:\n",
    "        print(f'{word}: {value * \"*\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 7: Функции высшего порядка для анализа текста\n",
    "\n",
    "Написать функцию `apply_analysis`, которая принимает список функций анализа и одну текстовую запись. Функция должна применять каждую функцию анализа к текстовой записи и возвращать словарь результатов.\n",
    "\n",
    "- Функция должна принимать следующие параметры:\n",
    "  - `text`: Один очищенный текст для анализа.\n",
    "  - `analysis_functions`: Список функций для применения к тексту. Каждая функция должна принимать на вход один текст и возвращать результат (например, частоту слов, анализ настроения).\n",
    "\n",
    "- Функция должна:\n",
    "  - Перебирать список функций анализа, применяя каждую из них к текстовой записи и сохраняя результат в словаре под описательным ключом (например, именем функции).\n",
    "  - Возвращать словарь, содержащий результаты всех примененных функций анализа.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_analysis(text, functions):\n",
    "    values = dict()\n",
    "    for func in functions:\n",
    "        values[func.__name__] = func(text)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 8: Обернуть всё в класс\n",
    "\n",
    "Создайте класс `TextAnalyzer`, который инкапсулирует всю функциональность из предыдущих задач. Класс должен включать методы для каждого из следующих действий:\n",
    "\n",
    "1. **Инициализация**:\n",
    "   - Класс должен принимать один текст при инициализации, хранить исходный текст и автоматически создавать его предобработанную версию.\n",
    "\n",
    "2. **Методы**:\n",
    "   - `word_frequency`: Анализирует частоту слов из предварительно обработанного текста.\n",
    "   - `extract_information`: Извлекает электронные письма, номера телефонов, даты, время и цены из предварительно обработанного текста.\n",
    "   - `analyze_sentiment`: Выполняет анализ настроения предварительно обработанного текста.\n",
    "   - `summarize_text`: Обобщает предварительно обработанный текст на основе коэффициента сжатия.\n",
    "   - `visualize_word_frequency`: Визуализирует данные о частоте слов в тексте.\n",
    "   - `apply_analysis`: Применяет список функций анализа к предварительно обработанному тексту.\n",
    "\n",
    "\n",
    "- Класс должен сохранять все необходимые внутренние состояния, такие как исходный и обработанный текст.\n",
    "- Каждый метод должен вызываться независимо, и класс должен позволять настраивать поведение там, где это возможно (например, передавать пользовательские списки слов или шаблоны regex).\n",
    "- Убедитесь, что методы хорошо документированы и что класс может быть легко инстанцирован с вводом текста для анализа.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import heapq\n",
    "\n",
    "class TextAnalyzer:\n",
    "    def __init__(self, text: str):\n",
    "        self.original_text = text\n",
    "        self.cleaned_text = self.preprocess_text()\n",
    "\n",
    "    def preprocess_text(self):\n",
    "        text = self.original_text.lower().strip()\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s.!?]', '', text) # del all trash symbols\n",
    "        text = re.sub(r'\\s+', ' ', text) # del all trash bspaces\n",
    "        text = re.sub(r'\\s([.!?])', r'\\1', text) # del bsaces before !?.\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text) # del acsess !?.\n",
    "        return text\n",
    "\n",
    "    def word_frequency(self, stop_words = [\"i\", \"and\", \"the\", \"is\", \"in\", \"it\", \"you\", \"that\", \"to\", \"of\", \"a\", \"with\", \"for\", \"on\", \"this\", \"at\", \"by\", \"an\", \"be\", \"should\"]) -> dict:\n",
    "        words = self.cleaned_text.split()\n",
    "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "        clean_words = [word.strip('.!?,') for word in filtered_words]\n",
    "        freq_dict = {}\n",
    "        for word in clean_words:\n",
    "            freq_dict[word] = freq_dict.get(word, 0) + 1\n",
    "        return freq_dict\n",
    "\n",
    "    def extract_information(self, \n",
    "                        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}',\n",
    "                        phone_pattern = r'\\+?\\d?\\(?\\d{3}\\)?[\\d -]{8,12}\\d',\n",
    "                        date_pattern = r'\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}\\b',\n",
    "                        time_pattern = r'\\b\\d{1,2}:\\d{2}\\s*[APap][mM]?\\b',\n",
    "                        price_pattern = r'\\$\\d+(?:\\.\\d{2})?', \n",
    "                        **patterns) -> dict:\n",
    "        default_patterns = {'emails': re.findall(email_pattern, self.original_text),\n",
    "            'phone_numbers': re.findall(phone_pattern, self.original_text),\n",
    "            'dates': re.findall(date_pattern, self.original_text),\n",
    "            'times': re.findall(time_pattern, self.original_text),\n",
    "            'prices': re.findall(price_pattern, self.original_text)}\n",
    "        for name, pattern in patterns.items():\n",
    "            default_patterns[name] = re.findall(pattern, self.original_text)\n",
    "        return default_patterns\n",
    "\n",
    "    def analyze_sentiment(self, positive_words=[\"good\", \"great\", \"happy\", \"joy\", \"excellent\", \"fantastic\", \"love\", \"best\", \"amazing\", \"fun\"],\n",
    "                      negative_words=[\"bad\", \"sad\", \"hate\", \"terrible\", \"awful\", \"poor\", \"worst\"]) -> int:\n",
    "        cleaned_words = [word.strip('.!?').lower() for word in self.original_text.split()]\n",
    "        positive_count = sum(cleaned_words.count(word) for word in positive_words)\n",
    "        negative_count = sum(cleaned_words.count(word) for word in negative_words)\n",
    "        sentiment_score = positive_count - negative_count \n",
    "        return sentiment_score\n",
    "\n",
    "    def summarize_text(self, compression_ratio=0.6, min_threshold=2):\n",
    "        text = self.cleaned_text\n",
    "        if not text or not text.strip():\n",
    "            return \"\"\n",
    "        sentences = [s.strip() for s in re.split(r'[.!?]', text) if s.strip()]\n",
    "        target_length = max(min_threshold, int(len(sentences) * (1 - compression_ratio)))\n",
    "        if len(sentences) <= target_length:\n",
    "            return '. '.join(sentences) + '.'\n",
    "    \n",
    "        def rank_sentences(sentences):\n",
    "            word_frequencies = {}\n",
    "            for sentence in sentences:\n",
    "                for word in sentence.split():\n",
    "                    word_lower = word.lower()\n",
    "                    if word_lower not in word_frequencies:\n",
    "                        word_frequencies[word_lower] = 0\n",
    "                    word_frequencies[word_lower] += 1\n",
    "            sentence_scores = {}\n",
    "            for sentence in sentences:\n",
    "                words = sentence.split()\n",
    "                sentence_scores[sentence] = sum(word_frequencies[word.lower()] for word in words)\n",
    "            return sentence_scores\n",
    "    \n",
    "        def recursive_summarization(sentences, target_length):\n",
    "            if len(sentences) <= target_length:\n",
    "                return sentences\n",
    "            sentence_scores = rank_sentences(sentences)\n",
    "            highest_ranked = max(sentence_scores, key=sentence_scores.get)\n",
    "            reduced_sentences = [s for s in sentences if s != highest_ranked]\n",
    "            return recursive_summarization(reduced_sentences, target_length)\n",
    "    \n",
    "        original_sentences = sentences[:]\n",
    "        summarized_sentences = recursive_summarization(sentences, target_length)\n",
    "        summarized_sentences.sort(key=lambda sentence: original_sentences.index(sentence))\n",
    "\n",
    "        return '. '.join(summarized_sentences) + '.'\n",
    "\n",
    "    def visualize_word_frequency(self, max_threshold=20):\n",
    "        word_frequency = self.word_frequency()\n",
    "        sorted_words = sorted(word_frequency.items(), key=lambda x: x[1], reverse=True)[:max_threshold]\n",
    "        for word, value in sorted_words:\n",
    "            print(f'{word}: {value * \"*\"}')\n",
    "\n",
    "    def apply_analysis(self, functions) -> dict:\n",
    "        text = self.original_text\n",
    "        values = dict()\n",
    "        for func in functions:\n",
    "            values[func.__name__] = func(text)\n",
    "        return values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 9: Анализ текста\n",
    "\n",
    "Провести анализ текста. Воспользоваться разработанными инструментами, чтобы:\n",
    "\n",
    "- Нормализовать текст\n",
    "- Узнать наиболее часто встречающиеся слова\n",
    "- Оценить настроение текста\n",
    "- Определить основную информацию текста\n",
    "\n",
    "Представить результаты оценок и сделайть вывод о содержании текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal text:\n",
      " stellar blade is the latest exclusive to hit the playstation 5 that excels at delivering a highly riveting action rpg. shift up corporation has crafted an impressive linear title that takes influences from some of the most renowned games in recent times. even though the parallels are quite apparent stellar blade doesnt try to reinvent the wheel but rather refines what players are already familiar with. stellar blade is centered around eve a member of the 7th airborne division w.\n",
      "stellar: 3\n",
      "blade: 3\n",
      "are: 2\n",
      "latest: 1\n",
      "exclusive: 1\n",
      "hit: 1\n",
      "playstation: 1\n",
      "5: 1\n",
      "excels: 1\n",
      "delivering: 1\n",
      "highly: 1\n",
      "riveting: 1\n",
      "action: 1\n",
      "rpg: 1\n",
      "shift: 1\n",
      "up: 1\n",
      "corporation: 1\n",
      "has: 1\n",
      "crafted: 1\n",
      "impressive: 1\n",
      "linear: 1\n",
      "title: 1\n",
      "takes: 1\n",
      "influences: 1\n",
      "from: 1\n",
      "some: 1\n",
      "most: 1\n",
      "renowned: 1\n",
      "games: 1\n",
      "recent: 1\n",
      "times: 1\n",
      "even: 1\n",
      "though: 1\n",
      "parallels: 1\n",
      "quite: 1\n",
      "apparent: 1\n",
      "doesnt: 1\n",
      "try: 1\n",
      "reinvent: 1\n",
      "wheel: 1\n",
      "but: 1\n",
      "rather: 1\n",
      "refines: 1\n",
      "what: 1\n",
      "players: 1\n",
      "already: 1\n",
      "familiar: 1\n",
      "with: 1\n",
      "centered: 1\n",
      "around: 1\n",
      "eve: 1\n",
      "member: 1\n",
      "7th: 1\n",
      "airborne: 1\n",
      "division: 1\n",
      "w: 1\n",
      "mood text:\n",
      " 0\n",
      "important info:\n",
      " shift up corporation has crafted an impressive linear title that takes influences from some of the most renowned games in recent times. stellar blade is centered around eve a member of the 7th airborne division w.\n"
     ]
    }
   ],
   "source": [
    "# final_boss = '**_Stellar Blade_** is the latest exclusive to hit the PlayStation 5 that excels at delivering a highly riveting action RPG. Shift Up Corporation has crafted an impressive linear title that takes influences from some of the most renowned games in recent times. **Even though the parallels are quite apparent, _Stellar Blade_ doesn’t try to reinvent the wheel but rather refines what players are already familiar with.**  _Stellar Blade_ is centered around EVE, a member of the 7th Airborne Division w...'\n",
    "\n",
    "r = TextAnalyzer(TEXT)\n",
    "print('normal text:\\n', r.preprocess_text())\n",
    "word_count = r.word_frequency()\n",
    "for word, frequency in sorted(word_count.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'{word}: {frequency}')\n",
    "print('mood text:\\n', r.analyze_sentiment())\n",
    "print('important info:\\n', r.summarize_text(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### АНАЛИЗ РЕЗУЛЬТАТОВ:\n",
    "\n",
    "Нормализация: текст очищен от спецсимволов, сохранена структура предложений, удалены лишние пробелы и форматирование\n",
    "\n",
    "Частотный анализ:показана частоты слов, удалены стоп-слова\n",
    "\n",
    "Тональность: текст средней эмоцианальности, кол-во хороших и плохих слов одинаковое\n",
    "\n",
    "Ключевая информация:\n",
    "Название игры: Stellar Blade\n",
    "Платформа: PlayStation 5\n",
    "Жанр: action RPG\n",
    "Разработчик: Shift Up Corporation\n",
    "\n",
    "Общий вывод: Текст представляет собой профессиональный обзор игры, написанный с позитивом. Автор считает игру качественным и оценил ее преемственность с другими сериями жанра. Текст информативен, содержит ключевые детали об игре\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***ОБЩИЙ ВЫВОД ПО РАБОТЕ:***\n",
    "*В рамках выполнения задания была реализована программа для анализа текстов, соответствующая поставленной задаче. Основная цель заключалась в создании инструмента, который позволяет обработать текстовые данные и получить их ключевые характеристики.Работа позволила углубить мои знания в области анализа данных и программирования, а также приобрести практический опыт в создании аналитических инструментов.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
