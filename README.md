# Инструмент для анализа текста

**Цель проекта**: Создание мощного инструмента для анализа текстовых данных, который может обрабатывать различные типы текста (отзывы пользователей, статьи, отрывки из книг) и предоставлять глубокий анализ, статистику и преобразования. 

## Часть 1: Предварительная обработка текста

В основе проекта лежит функция `preprocess_text`, которая очищает входной текст. Функционал включает:
   - Преобразование текста в нижний регистр
   - Удаление лишних знаков препинания с сохранением основных (`.` `!` `?`)
   - Нормализацию пробелов
   - Возврат очищенного текста

**Реализация**:
   - Использует базовые методы работы со строками и регулярные выражения
   - Сохраняет важные знаки препинания в конце предложений
   - Удаляет технические символы и лишние пробелы

**Пример использования**:
```python
input_texts = [
    "Hello, World!\n   This is a test...",
    "Python is fun!!! #coding",
    "  Spaces should be    removed."
]

# Результат:
# [
#     "hello world! this is a test.",
#     "python is fun! coding",
#     "spaces should be removed."
# ]
```

## Часть 2: Анализ частотности слов

Модуль частотного анализа включает функцию `word_frequency`, которая анализирует встречаемость слов в тексте. Особенности:
   - Подсчёт частоты каждого слова
   - Фильтрация стоп-слов
   - Возможность настройки списка стоп-слов

**Базовый список стоп-слов**:
```python
stop_words = ["and", "the", "is", "in", "it", "you", "that", "to", "of", "a", "with", "for", "on", "this", "at", "by", "an", "should", "be"]
```

**Особенности реализации**:
   - Использование словаря для эффективного подсчёта
   - Нечувствительность к регистру
   - Гибкая система фильтрации стоп-слов

**Пример использования**:
```python
input_text = "hello world this is a test. python is fun coding. spaces should be removed."

# С использованием базовых стоп-слов

# Результат:
# {
#     "hello": 1,
#     "world": 1,
#     "test": 1,
#     "python": 1,
#     "fun": 1,
#     "coding": 1,
#     "spaces": 1,
#     "removed": 1
# }
```

[продолжение следует в следующих частях...]

## Часть 3: Извлечение информации

Модуль извлечения информации включает функцию `extract_information`, которая использует настраиваемые регулярные выражения для поиска различных типов данных. 

**Поддерживаемые типы данных**:
1. Email адреса
2. Телефонные номера
3. Даты
4. Время
5. Цены
6. Пользовательские шаблоны

**Особенности реализации**:
- Гибкая система шаблонов с настройками по умолчанию:
  - `email_pattern`
  - `phone_pattern`
  - `date_pattern`
  - `time_pattern`
  - `price_pattern`
  - Поддержка пользовательских шаблонов

**Пример использования**:
```python
input_text = "Contact me at john.doe@example.com or call +123 456 7890. Meeting on 10/05/2024 at 3:00 PM. The price is $19.99. Birthday on 15-08-2023."

# Результат:
# {
#     "emails": ["john.doe@example.com"],
#     "phone_numbers": ["+123 456 7890"],
#     "dates": ["10/05/2024", "15-08-2023"],
#     "times": ["3:00 PM"],
#     "prices": ["$19.99"]
# }
```

## Часть 4: Анализ тональности

Модуль анализа тональности текста включает функцию `analyze_sentiment`, которая оценивает эмоциональную окраску текста на основе словарей позитивных и негативных слов.

**Базовые словари**:
```python
positive_words = ["good", "great", "happy", "joy", "excellent", "fantastic", "love", "best"]
negative_words = ["bad", "sad", "hate", "terrible", "awful", "poor", "worst"]
```

**Особенности реализации**:
- Настраиваемые словари через keyword-аргументы
- Подсчёт позитивных и негативных слов
- Расчёт общего показателя тональности

**Пример использования**:
```python
example_texts = [
    "I love this product! It's fantastic and makes me very happy.",
    "This is the worst experience I've ever had.",
    "Great service but the food was bad."
]

# Результат:
{
    "I love this product! It's fantastic and makes me very happy.": 3,
    "This is the worst experience I've ever had.": -1,
    "Great service but the food was bad.": 0
}
```

## Часть 5: Автоматическое резюмирование текста

Модуль резюмирования включает функцию `summarize_text`, которая создаёт краткие версии текста, сохраняя наиболее важную информацию. 

**Основные характеристики**:
- Настраиваемый коэффициент сжатия
- Рекурсивный алгоритм отбора предложений
- Интеллектуальное ранжирование важности информации

**Параметры функции**:
- `text`: Входной текст для обработки
- `compression_ratio`: Коэффициент сжатия (0-1)
- `min_threshold`: Минимальное количество предложений в результате

**Особенности реализации**:
- Умное разделение на предложения
- Многофакторное ранжирование предложений
- Динамический отбор наиболее значимого контента
- Сохранение связности текста

**Пример использования**:
```python
input_text = (
    "I love this product! It's fantastic and makes me very happy. "
    "This is the worst experience I've ever had. "
    "Great service but the food was bad. "
    "The atmosphere was amazing, and the location is perfect."
)

# При коэффициенте сжатия 0.6
# Результат:
# "I love this product! It's fantastic and makes me very happy. The atmosphere was amazing, and the location is perfect."
```

## Часть 6: Визуализация частотности

Модуль визуализации включает функцию `visualize_word_frequency`, которая создаёт наглядное представление частотности слов в текстовом формате.

**Функциональность**:
- Создание визуальных гистограмм в ASCII
- Масштабируемое отображение частот
- Настраиваемый порог отображения
- Сортировка по частоте

**Особенности реализации**:
- Автоматическое масштабирование для читаемости
- Ограничение вывода через `max_threshold`
- Интуитивно понятное представление данных

**Пример использования**:
```python
word_frequencies = {
    "hello": 5,
    "world": 3,
    "python": 4,
    "coding": 2
}

# Результат:
# hello:  *****
# python: ****
# world:  ***
# coding: **
```

## Часть 7: Высокоуровневый анализ

Модуль высокоуровневого анализа включает функцию `apply_analysis`, которая позволяет комбинировать различные виды анализа в единый процесс.

**Возможности**:
- Применение множества аналитических функций
- Агрегация результатов в единый отчёт
- Гибкая настройка набора анализов

**Принцип работы**:
- Приём списка аналитических функций
- Последовательное применение к тексту
- Формирование структурированного отчёта

**Пример использования**:
```python
def word_frequency(text):
    # Реализация анализа частотности
    pass

def analyze_sentiment(text):
    # Реализация анализа тональности
    pass

input_text = "I love this product! It's fantastic and makes me very happy."

results = apply_analysis(input_text, [word_frequency, analyze_sentiment])

# Результат:
# {
#     "word_frequency": {"love": 1, "product": 1, "fantastic": 1, "happy": 1},
#     "sentiment": 3
# }
```

## Часть 8: Объектно-ориентированная реализация

Весь функционал проекта инкапсулирован в класс `TextAnalyzer`, который предоставляет удобный интерфейс для работы со всеми компонентами системы.

**Основные методы**:
- `word_frequency`: Анализ частотности слов
- `extract_information`: Извлечение структурированных данных
- `analyze_sentiment`: Анализ тональности
- `summarize_text`: Создание краткого содержания
- `visualize_word_frequency`: Визуализация результатов
- `apply_analysis`: Комплексный анализ

**Архитектурные особенности**:
- Сохранение состояния между операциями
- Кэширование промежуточных результатов
- Гибкая система настроек
- Расширяемая архитектура

**Пример использования**:
```python
class TextAnalyzer:
    def __init__(self, text: str):
        self.original_text = text
        self.cleaned_text = self.preprocess_text(text)

    def word_frequency(self) -> dict:
        # Реализация анализа частотности
        pass

    def extract_information(self, **patterns) -> dict:
        # Реализация извлечения информации
        pass

    def analyze_sentiment(self, positive_words=None, negative_words=None) -> int:
        # Реализация анализа тональности
        pass

    def summarize_text(self, compression_ratio: float) -> str:
        # Реализация резюмирования
        pass

    def visualize_word_frequency(self) -> None:
        # Реализация визуализации
        pass

    def apply_analysis(self, analysis_functions: list) -> dict:
        # Реализация комплексного анализа
        pass

# Использование
analyzer = TextAnalyzer("Пример текста для анализа")
analyzer.visualize_word_frequency()
```

## Применение проекта

Инструмент может быть использован для:
- Анализа пользовательских отзывов
- Обработки новостных статей
- Исследования литературных текстов
- Анализа социальных медиа
- Работы с документацией

### Возможные направления развития:
1. Добавление поддержки многоязычности
2. Интеграция с ML моделями
3. Создание веб-интерфейса
4. Расширение функционала визуализации
5. Оптимизация производительности

### Технологии:
- Python 3.8+
- Регулярные выражения
- Объектно-ориентированное программирование
- Алгоритмы обработки текста
- Методы визуализации данных